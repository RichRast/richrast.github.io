---
layout: page
title: Main
weight: 1.5
show: 1
---

<div class="col-7">
    <center>
  <table>
<tr><td style="padding:10px 90px 10px 0px">
      <img width="200px" class="img-rounded" src="./images/richras_profile.jpg" />
  </td><td style="padding:10px">
    <center>
    <h1>Richa Rastogi</h1>
    <span style="font-size:16px"><a href="https://scholar.google.com/citations?hl=en&user=hhy7tVIAAAAJ&view_op=list_works&sortby=pubdate">[Google Scholar]</a></span> </h1> <br>
</center>

      </td>
  </tr>
  </table>
  </center>
<br>
</div>

<p style="font-size: 16px">

Hi! I'am a Computer Science PhD Candidate at <a href="https://www.cs.cornell.edu/">Cornell University </a> and I'am very fortunate to be advised by Professor <a href="https://www.cs.cornell.edu/people/tj/">Thorsten Joachims</a>. 
<br>
My research interests broadly lie in the area of learning from feedback in interactive systems ranging from recommender to text generation systems. 
My recent work proposes a framework to tractably align these systems with long term objectives. I am also interested in the area of algorithmic fairness, such as fairness in ranking.

<br>
<br>
Prior to starting PhD, I spent several years working as a Controls Software Engineer at <a href="https://youtu.be/3bdRKaodLK8?si=6W3vaqLnhWNxdbfP">Amazon Fullfillment Technologies</a> and other companies. Prior to that, I completed a Masters in Industrial Engineering and Operations Research at <a href="https://www.isye.gatech.edu/">ISyE, Georgia Tech </a>
and a Bachelors of Engineering at <a href="http://nsut.ac.in/en/home">Delhi University, India</a>.

<br>

</p>
<!-- <h4> News </h4>
<ul style="font-size: 16px">
    <li>08/24: Our paper, <a href="https://arxiv.org/abs/2309.01610">Fairness in Ranking under Disparate Uncertainty</a> is accepted at ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO'24). See you in Mexico!
    </li>
    <!-- <br> -->
    <li>07/24: I will be at the <a  href="https://ghc.anitab.org/">Grace Hopper Celebration of Women in Computing</a> in Philadelphia. Come stop by the Cornell booth to chat !
    </li>
    <!-- <br> -->
    <li>06/24: Short version of our paper <a href="https://openreview.net/forum?id=QhXBXekwVm">MultiScale Policy Learning for Alignment with Long Term Objectives</a> is accepted at the ICML Models of Human Feedback for AI Alignment workshop. See you in Vienna!
    </li>
    <!-- <br> -->
    <li>08/23: Presented our paper, <a href="https://arxiv.org/abs/2309.01610">Fairness in Ranking under Disparate Uncertainty</a>, as a <b> Spotlight (Oral) </b> at UAI workshop on <a href="https://sites.google.com/view/epi-workshop-uai-2023/schedule?authuser=0">Epistemic AI</a> at CMU, Pittsburgh! 
        We introduce Equal-Opportunity Ranking (EOR) as a new fairness criterion for ranking that provably reduces the group unfairness induced when 
        the uncertainty of the underlying relevance model differs between groups of candidates.
    </li>
    <!-- <br> -->
    <li>01/23: Our paper, <a href="https://arxiv.org/abs/2205.11718">Semi-Parametric Inducing Point Networks and Neural Processes</a>, is accepted at International Conference on Learning Representations (ICLR '23)! We introduce 
        semi-parametric inducing point networks (SPIN), a general-purpose architecture that can query the training set at inference time in a compute-efficient manner. 
    </li>
    <!-- <br> -->
    <li>08/21: Our <a href="https://patents.google.com/patent/US11104469B1/en?oq=US11104469B1">Patent</a> filed on behalf of Amazon is granted by USPTO! It describes a closed loop feedback 
        dynamical system with online updates for accurately positioning labels on moving packages. 
    </li>
    <!-- <br> -->
</ul> -->



<h4>Selected Works</h4>

<p>
  
  
    <!-- My full list of papers and patents are available <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=hhy7tVIAAAAJ&sortby=pubdate">here</a>. -->
    </p>
    <table>
    {% for paper in site.data.papers.papers %}
    
    
      <tr><td style="padding:10px">
          {% if paper.image %}
          <a href="{{paper.pdf}}"><img width="600px" style="min-width:150px" src="{{paper.image}}"></a>
          {% else %}
          <a href="{{paper.pdf}}"><img height="75px" style="min-width:150px" src="https://avatar.tobi.sh/{{paper.title}}"></a>
          {% endif %}
    </td><td style="padding:10px">
    <a class="paper" href="{{paper.pdf}}">
    {{paper.title}}
    </a><br>
    {{paper.authors}}.<br>
    {{paper.conference}} <br>
    {{paper.tldr}} <br>
    {% if paper.code %} <a class="icon slides label label-success label-warning" href="{{paper.code}}">code</a>{% endif %} 
    {% if paper.poster %} <a class="icon slides label label-success label-warning" href="{{paper.poster}}">poster</a>{% endif %} <br>
    {% if paper.bibtex %} <a class="icon slides label label-success label-warning" href="{{paper.bibtex}}">bibtex</a>{% endif %} <br>
    <!-- {% if paper.pdf %}<a class="icon pdf label label-info" href="{{paper.pdf}}">pdf</a> {% endif %}
    {% if paper.models %}<a class="icon slides label label-warning" href="{{paper.models}}">models</a>{% endif %}
    -->
    <br>
    
    </td></tr>
    
    {% endfor %}
    </table>

<br>    

